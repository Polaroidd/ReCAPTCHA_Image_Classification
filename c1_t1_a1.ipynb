{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95866fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b788f429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bicycle', 'Bridge', 'Bus', 'Car', 'Chimney', 'Crosswalk', 'Hydrant', 'Motorcycle', 'Palm', 'Traffic Light']\n",
      "Bicycle 468\n",
      "Bridge 765\n",
      "Bus 1170\n",
      "Car 453\n",
      "Chimney 198\n",
      "Crosswalk 462\n",
      "Hydrant 714\n",
      "Motorcycle 156\n",
      "Palm 339\n",
      "Traffic Light 288\n"
     ]
    }
   ],
   "source": [
    "folder_path = './recaptcha-dataset/Large'\n",
    "class_D = {}\n",
    "files_and_folders = os.listdir(folder_path)\n",
    "\n",
    "# 해당 경로의 모든 파일 및 폴더 이름 리스트 반환\n",
    "files_and_folders = os.listdir(folder_path)\n",
    "\n",
    "# 폴더 이름만 필터링하여 리스트에 저장\n",
    "folder_names = [f for f in files_and_folders if os.path.isdir(os.path.join(folder_path, f))]\n",
    "folder_dic = {}\n",
    "print(folder_names)\n",
    "for a in folder_names:\n",
    "    folder_dic[a] = os.listdir(folder_path+\"/\"+a)\n",
    "    print(a, len(folder_dic[a]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1af65bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_hist(hist):\n",
    "   #정규화 => 이미지 크기에 상관없이 히스토그램 그려줘 - 모든 값 0-1 매핑핑\n",
    "    # Normalize the histogram\n",
    "    hist = hist.astype('float')\n",
    "    hist /= hist.sum()\n",
    "    return hist\n",
    "\n",
    "\n",
    "def hist_gram(image):\n",
    "    hist_b, bins_b = np.histogram(image[0], bins=128, range=(0, 256)) #bin 만큼의 차원의 feature 뽑을 수 있다.\n",
    "    hist_g, bins_g = np.histogram(image[1], bins=128, range=(0, 256))\n",
    "    hist_r, bins_r = np.histogram(image[2], bins=128, range=(0, 256))\n",
    "    hist_b = norm_hist(hist_b)    # 256-d\n",
    "    hist_g = norm_hist(hist_g)    # 256-d\n",
    "    hist_r = norm_hist(hist_r)    # 256-d\n",
    "    # gray histogram 입력을 grat -> bin을 128 -> 사실은 띄워져 있다.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    hist_gray, bins_gray = np.histogram(gray, bins=128, range=(0, 256))\n",
    "    hist_gray = norm_hist(hist_gray)    # 128-d\n",
    "\n",
    "    return hist_b, hist_g, hist_r, hist_gray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbfc8ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Law's texture\n",
    "from scipy import signal as sg\n",
    "\n",
    "def laws_texture(gray):\n",
    "    (rows, cols) = gray.shape[:2] #행과 열의 개수 - 크기기\n",
    "    \n",
    "    #gray scale에 대해 smoothing한 이미지를 원본에서 빼준다. 5*5짜리의 mean 필터를 적용해줬다.\n",
    "    smooth_kernel = (1/25)*np.ones((5,5))\n",
    "    gray_smooth = sg.convolve(gray, smooth_kernel,\"same\")\n",
    "    gray_processed = np.abs(gray - gray_smooth)\n",
    "    \n",
    "\n",
    "    filter_vectors = np.array([[ 1,  4,  6,  4, 1],    # L5\n",
    "                               [-1, -2,  0,  2, 1],    # E5\n",
    "                               [-1,  0,  2,  0, 1],    # S5\n",
    "                               [ 1, -4,  6, -4, 1]])   # R5\n",
    "\n",
    "    # 0:L5L5, 1:L5E5, 2:L5S5, 3:L5R5, \n",
    "    # 4:E5L5, 5:E5E5, 6:E5S5, 7:E5R5,\n",
    "    # 8:S5L5, 9:S5E5, 10:S5S5, 11:S5R5, \n",
    "    # 12:R5L5, 13:R5E5, 14:R5S5, 15:R5R5\n",
    "    filters = list()\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            filters.append(np.matmul(filter_vectors[i][:].reshape(5,1),\n",
    "                                     filter_vectors[j][:].reshape(1,5)))\n",
    "\n",
    "    conv_maps = np.zeros((rows, cols,16))\n",
    "    for i in range(len(filters)):\n",
    "        conv_maps[:, :, i] = sg.convolve(gray_processed,\n",
    "                                         filters[i],'same')\n",
    "    #16개의 값 중 가장 중요한 9개 선정\n",
    "    texture_maps = list()\n",
    "    texture_maps.append((conv_maps[:, :, 1]+conv_maps[:, :, 4])//2)     # L5E5 / E5L5\n",
    "    texture_maps.append((conv_maps[:, :, 2]+conv_maps[:, :, 8])//2)     # L5S5 / S5L5\n",
    "    texture_maps.append((conv_maps[:, :, 3]+conv_maps[:, :, 12])//2)    # L5R5 / R5L5\n",
    "    texture_maps.append((conv_maps[:, :, 7]+conv_maps[:, :, 13])//2)    # E5R5 / R5E5\n",
    "    texture_maps.append((conv_maps[:, :, 6]+conv_maps[:, :, 9])//2)     # E5S5 / S5E5 \n",
    "    texture_maps.append((conv_maps[:, :, 11]+conv_maps[:, :, 14])//2)   # S5R5 / R5S5\n",
    "    texture_maps.append(conv_maps[:, :, 10])                            # S5S5\n",
    "    texture_maps.append(conv_maps[:, :, 5])                             # E5E5\n",
    "    texture_maps.append(conv_maps[:, :, 15])                            # R5R5\n",
    "    texture_maps.append(conv_maps[:, :, 0])                             # L5L5 (use to norm TEM)하나의 feature 값으로 저장하길 원하기에 normalization => 9개의 숫자가 나온다.\n",
    "#숫자 9개로 나오게 하려고고\n",
    "\n",
    "\n",
    "    TEM = list()\n",
    "    for i in range(9):\n",
    "        TEM.append(np.abs(texture_maps[i]).sum() / np.abs(texture_maps[9]).sum())\n",
    "        \n",
    "    return TEM\n",
    "\n",
    "# laws = laws_texture(gray)    # 9-d laws_texture 직접 함수로 구현하기! - 특징 벡터 제일 많이 쓸겨!\n",
    "# print(laws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bb90c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "recaptcha = './recaptcha-dataset/Large'\n",
    "query_path = './query'\n",
    "# labels = ['Bicycle', 'Bridge', 'Bus', 'Car', \n",
    "#           'Crosswalk', 'Motorcycle']\n",
    "labels = ['Bicycle', 'Bridge', 'Bus', 'Car', 'Chimney', \n",
    "           'Crosswalk', 'Hydrant', 'Motorcycle', 'Palm', 'Traffic Light']\n",
    "\n",
    "sbt_train_features = []\n",
    "sbt_train_labels = []\n",
    "q_sbt_test_features = []\n",
    "\n",
    "for label in labels:\n",
    "    image_dir = os.path.join(recaptcha, label)\n",
    "    image_list = os.listdir(image_dir)\n",
    "    for i, image_name in enumerate(image_list):\n",
    "\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "        if i < 150:\n",
    "            sbt_train_features.append(laws_texture(gray_img))\n",
    "            sbt_train_labels.append(label)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "query_list = os.listdir(query_path)\n",
    "for i, q_name in enumerate(query_list):\n",
    "        \n",
    "        q_path = os.path.join(query_path, q_name)\n",
    "        image = cv2.imread(q_path)\n",
    "        image = cv2.resize(cv2.imread(q_path),(120,120))\n",
    "        \n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    " \n",
    "        if i < 100:\n",
    "            q_sbt_test_features.append(laws_texture(gray_img))\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b71fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import local_binary_pattern\n",
    "\n",
    "recaptcha = './recaptcha-dataset/Large'\n",
    "# labels = ['Bicycle', 'Bridge', 'Bus', 'Car', \n",
    "#           'Crosswalk', 'Motorcycle']\n",
    "labels = ['Bicycle', 'Bridge', 'Bus', 'Car', 'Chimney', \n",
    "           'Crosswalk', 'Hydrant', 'Motorcycle', 'Palm', 'Traffic Light']\n",
    "\n",
    "lbp_train_features = []\n",
    "lbp_train_labels = []\n",
    "q_lbp_test_features = []\n",
    "\n",
    "for label in labels:\n",
    "    image_dir = os.path.join(recaptcha, label)\n",
    "    image_list = os.listdir(image_dir)\n",
    "    for i, image_name in enumerate(image_list):\n",
    "\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        img = cv2.imread(image_path)\n",
    "\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        lbp = local_binary_pattern(gray_img, P=8, R=1) #R=1 -> 바로 인접 8개의 픽셀값 고려하겠다. 더 멀리 보려면 R을 늘려려\n",
    "\n",
    "        hist_lbp, bin_lbp = np.histogram(lbp.ravel(), bins=64, range=(0, 256)) #256차원을 bin값으로 축소할수도!\n",
    "        hist_lbp = norm_hist(hist_lbp)    # 64-d\n",
    "\n",
    "\n",
    "        if i < 150:\n",
    "            lbp_train_features.append(hist_lbp)\n",
    "            lbp_train_labels.append(label)\n",
    "\n",
    "        else:\n",
    "            break\n",
    "\n",
    "query_list = os.listdir(query_path)\n",
    "for i, q_name in enumerate(query_list):\n",
    "        \n",
    "        q_path = os.path.join(query_path, q_name)\n",
    "        image = cv2.resize(cv2.imread(q_path),(120,120))\n",
    "        gray_img = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        lbp = local_binary_pattern(gray_img, P=8, R=1) #R=1 -> 바로 인접 8개의 픽셀값 고려하겠다. 더 멀리 보려면 R을 늘려려\n",
    "\n",
    "        hist_lbp, bin_lbp = np.histogram(lbp.ravel(), bins=64, range=(0, 256)) #256차원을 bin값으로 축소할수도!\n",
    "        hist_lbp = norm_hist(hist_lbp)    # 64-d\n",
    "\n",
    "        if i < 100:\n",
    "            q_lbp_test_features.append(hist_lbp)\n",
    "        else:\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e8fa3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bus' 'Palm' 'Hydrant' 'Hydrant' 'Chimney' 'Bridge' 'Bus' 'Palm'\n",
      " 'Motorcycle' 'Bus' 'Palm' 'Bicycle' 'Crosswalk' 'Car' 'Crosswalk'\n",
      " 'Hydrant' 'Bicycle' 'Chimney' 'Hydrant' 'Bicycle' 'Palm' 'Car' 'Bicycle'\n",
      " 'Bridge' 'Palm' 'Hydrant' 'Palm' 'Chimney' 'Chimney' 'Bus' 'Palm'\n",
      " 'Chimney' 'Bridge' 'Chimney' 'Hydrant' 'Car' 'Car' 'Chimney' 'Chimney'\n",
      " 'Palm' 'Bicycle' 'Chimney' 'Chimney' 'Bicycle' 'Bus' 'Hydrant' 'Hydrant'\n",
      " 'Crosswalk' 'Bus' 'Hydrant' 'Crosswalk' 'Bicycle' 'Chimney' 'Bridge'\n",
      " 'Hydrant' 'Bridge' 'Hydrant' 'Traffic Light' 'Bicycle' 'Bus' 'Palm'\n",
      " 'Crosswalk' 'Crosswalk' 'Bus' 'Crosswalk' 'Hydrant' 'Palm' 'Bus'\n",
      " 'Bicycle' 'Crosswalk' 'Bicycle' 'Hydrant' 'Motorcycle' 'Car' 'Chimney'\n",
      " 'Crosswalk' 'Car' 'Hydrant' 'Bicycle' 'Crosswalk' 'Hydrant' 'Hydrant'\n",
      " 'Crosswalk' 'Chimney' 'Bicycle' 'Bicycle' 'Chimney' 'Hydrant' 'Bus'\n",
      " 'Chimney' 'Bicycle' 'Bicycle' 'Hydrant' 'Palm' 'Car' 'Bicycle' 'Palm'\n",
      " 'Palm' 'Hydrant' 'Hydrant']\n"
     ]
    }
   ],
   "source": [
    "lst = []\n",
    "for i in range(len(sbt_train_features)):\n",
    "    npa = np.array(sbt_train_features[i])\n",
    "    lst.append(npa)\n",
    "final_train_features = np.concatenate([lbp_train_features, lst], axis = 1)\n",
    "Lst = []\n",
    "for i in range(len(q_sbt_test_features)):\n",
    "    npa = np.array(q_sbt_test_features[i])\n",
    "    Lst.append(npa)\n",
    "final_test_features = np.concatenate([q_lbp_test_features, Lst], axis = 1)\n",
    "\n",
    "final_classifier = KNeighborsClassifier(n_neighbors = 10)\n",
    "\n",
    "final_classifier.fit(final_train_features, lbp_train_labels)\n",
    "final_predict_labels = final_classifier.predict(final_test_features)\n",
    "print(final_predict_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "15ab8006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['query1.png', 'query10.png', 'query100.png', 'query11.png', 'query12.png', 'query13.png', 'query14.png', 'query15.png', 'query16.png', 'query17.png', 'query18.png', 'query19.png', 'query2.png', 'query20.png', 'query21.png', 'query22.png', 'query23.png', 'query24.png', 'query25.png', 'query26.png', 'query27.png', 'query28.png', 'query29.png', 'query3.png', 'query30.png', 'query31.png', 'query32.png', 'query33.png', 'query34.png', 'query35.png', 'query36.png', 'query37.png', 'query38.png', 'query39.png', 'query4.png', 'query40.png', 'query41.png', 'query42.png', 'query43.png', 'query44.png', 'query45.png', 'query46.png', 'query47.png', 'query48.png', 'query49.png', 'query5.png', 'query50.png', 'query51.png', 'query52.png', 'query53.png', 'query54.png', 'query55.png', 'query56.png', 'query57.png', 'query58.png', 'query59.png', 'query6.png', 'query60.png', 'query61.png', 'query62.png', 'query63.png', 'query64.png', 'query65.png', 'query66.png', 'query67.png', 'query68.png', 'query69.png', 'query7.png', 'query70.png', 'query71.png', 'query72.png', 'query73.png', 'query74.png', 'query75.png', 'query76.png', 'query77.png', 'query78.png', 'query79.png', 'query8.png', 'query80.png', 'query81.png', 'query82.png', 'query83.png', 'query84.png', 'query85.png', 'query86.png', 'query87.png', 'query88.png', 'query89.png', 'query9.png', 'query90.png', 'query91.png', 'query92.png', 'query93.png', 'query94.png', 'query95.png', 'query96.png', 'query97.png', 'query98.png', 'query99.png']\n"
     ]
    }
   ],
   "source": [
    "print(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f16cbbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#지금까지 구한 특징들에서 n차원 특징을 뽑고, KNN 사용해서 classification 할겨!\n",
    "recaptcha = './recaptcha-dataset/Large'\n",
    "labels = ['Bicycle', 'Bridge', 'Bus', 'Car', 'Chimney', \n",
    "          'Crosswalk', 'Hydrant', 'Motorcycle', 'Palm', 'Traffic Light']\n",
    "\n",
    "c_train_features = []\n",
    "c_train_labels = []\n",
    "c_test_features = []\n",
    "c_test_labels = []\n",
    "g_train_features = []\n",
    "g_test_features = []\n",
    "\n",
    "#Texture - color image + SVD?\n",
    "for label in labels:\n",
    "    image_dir = os.path.join(recaptcha, label)\n",
    "    image_list = os.listdir(image_dir)\n",
    "    for i, image_name in enumerate(image_list):\n",
    "        image_path = os.path.join(image_dir, image_name)\n",
    "        img = cv2.resize(cv2.imread(image_path),(120,120))\n",
    "        \n",
    "        hist_b, hist_g, hist_r, hist_gray = hist_gram(img)\n",
    "        \n",
    "        if i <150:#train 이거 숫자 바꿔주면 돼돼\n",
    "            c_train_features.append(hist_b+hist_g+hist_r) #feature\n",
    "            g_train_features.append(hist_gray)\n",
    "            c_train_labels.append(label) #label\n",
    "\n",
    "        else:\n",
    "            break\n",
    "query_list = os.listdir(query_path)\n",
    "for i, q_name in enumerate(query_list):\n",
    "        q_path = os.path.join(query_path, q_name)\n",
    "        image = cv2.imread(q_path)\n",
    "        \n",
    "        hist_b, hist_g, hist_r, hist_gray = hist_gram(image)\n",
    "        \n",
    "        if i < 100:\n",
    "            c_test_features.append(hist_r+hist_g+hist_b)\n",
    "        else:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "46f902c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bus' 'Palm' 'Hydrant' 'Hydrant' 'Chimney' 'Bridge' 'Bus' 'Palm'\n",
      " 'Crosswalk' 'Bus' 'Palm' 'Chimney' 'Crosswalk' 'Car' 'Crosswalk'\n",
      " 'Hydrant' 'Crosswalk' 'Chimney' 'Hydrant' 'Hydrant' 'Palm' 'Bus'\n",
      " 'Bicycle' 'Crosswalk' 'Palm' 'Chimney' 'Chimney' 'Chimney' 'Chimney'\n",
      " 'Bus' 'Palm' 'Motorcycle' 'Bridge' 'Chimney' 'Car' 'Car' 'Car' 'Chimney'\n",
      " 'Chimney' 'Palm' 'Bicycle' 'Chimney' 'Chimney' 'Hydrant' 'Bus'\n",
      " 'Motorcycle' 'Bicycle' 'Crosswalk' 'Hydrant' 'Hydrant' 'Bridge' 'Palm'\n",
      " 'Chimney' 'Bridge' 'Hydrant' 'Crosswalk' 'Hydrant' 'Motorcycle' 'Bicycle'\n",
      " 'Bus' 'Palm' 'Crosswalk' 'Crosswalk' 'Bus' 'Crosswalk' 'Bicycle' 'Palm'\n",
      " 'Bus' 'Crosswalk' 'Bicycle' 'Hydrant' 'Hydrant' 'Car' 'Car' 'Bus'\n",
      " 'Crosswalk' 'Crosswalk' 'Hydrant' 'Crosswalk' 'Crosswalk' 'Hydrant' 'Bus'\n",
      " 'Crosswalk' 'Chimney' 'Crosswalk' 'Chimney' 'Chimney' 'Hydrant' 'Bus'\n",
      " 'Chimney' 'Crosswalk' 'Bicycle' 'Hydrant' 'Chimney' 'Car' 'Chimney'\n",
      " 'Palm' 'Chimney' 'Hydrant' 'Hydrant']\n",
      "['query1.png', 'query10.png', 'query100.png', 'query11.png', 'query12.png', 'query13.png', 'query14.png', 'query15.png', 'query16.png', 'query17.png', 'query18.png', 'query19.png', 'query2.png', 'query20.png', 'query21.png', 'query22.png', 'query23.png', 'query24.png', 'query25.png', 'query26.png', 'query27.png', 'query28.png', 'query29.png', 'query3.png', 'query30.png', 'query31.png', 'query32.png', 'query33.png', 'query34.png', 'query35.png', 'query36.png', 'query37.png', 'query38.png', 'query39.png', 'query4.png', 'query40.png', 'query41.png', 'query42.png', 'query43.png', 'query44.png', 'query45.png', 'query46.png', 'query47.png', 'query48.png', 'query49.png', 'query5.png', 'query50.png', 'query51.png', 'query52.png', 'query53.png', 'query54.png', 'query55.png', 'query56.png', 'query57.png', 'query58.png', 'query59.png', 'query6.png', 'query60.png', 'query61.png', 'query62.png', 'query63.png', 'query64.png', 'query65.png', 'query66.png', 'query67.png', 'query68.png', 'query69.png', 'query7.png', 'query70.png', 'query71.png', 'query72.png', 'query73.png', 'query74.png', 'query75.png', 'query76.png', 'query77.png', 'query78.png', 'query79.png', 'query8.png', 'query80.png', 'query81.png', 'query82.png', 'query83.png', 'query84.png', 'query85.png', 'query86.png', 'query87.png', 'query88.png', 'query89.png', 'query9.png', 'query90.png', 'query91.png', 'query92.png', 'query93.png', 'query94.png', 'query95.png', 'query96.png', 'query97.png', 'query98.png', 'query99.png']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "c_final_classifier = KNeighborsClassifier(n_neighbors = 15)\n",
    "\n",
    "c_final_classifier.fit(lbp_train_features, lbp_train_labels)\n",
    "c_final_predict_labels = c_final_classifier.predict(q_lbp_test_features)\n",
    "print(c_final_predict_labels)\n",
    "print(query_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb5b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "792185eb",
   "metadata": {},
   "source": [
    "### Task1 : Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d35e245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "with open('c1_t1_a1.csv','w') as file :\n",
    "    write = csv.writer(file)\n",
    "    for i in range(len(c_final_predict_labels)):\n",
    "        write.writerow([query_list[i]] + [final_predict_labels[i]])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435c43d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
